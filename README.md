# Fraud Analysis

## Description

This repository contains the scripts used to analyze the dataset generated by the companion repository [`fraud-webscraper`](https://github.com/your-username/fraud-webscraper).  
It supports replication of the experiments presented in the master's thesis **"Machine Learning Methods for Text-Based Fraud Detection"** authored by Moustafa Amin and supervised by Dr. Matthias Aßenmacher at the Statistics Institute of Ludwig Maximilian University of Munich.

There are two companion repositories:

- [`fraud-webscraper`](https://github.com/your-username/fraud-webscraper): Contains web crawlers and data collection scripts used to generate the data
- [`fraud-report`](https://github.com/your-username/fraud-report): LaTeX source and PDF of the thesis report

## Contents

- `amalgamate.py` – Combines the raw components from the webscraper into a unified dataset for experimentation
- `fraud_descriptives.ipynb` – Jupyter notebook with the descriptive statistics and plots featured in the [report](https://github.com/your-username/fraud-report)
- `requirements.txt` – Python packages required for replication
- `classifier/` – Contains scripts for running classifiers such as XGBoost and Random Forest on different input types:
  - `classifier.py` – Main script for training and evaluating classifiers
  - `tabularize.py` – Transforms tabular features into the required format for `classifier.py`
- `LDA/` – Scripts for topic modeling using Latent Dirichlet Allocation (LDA) on MD&A sections:
  - `lda_tuner.py` – Tunes the number of topics based on perplexity and coherence scores
  - `lda_classifier.py` – Trains classifiers on the LDA-transformed topic distributions
- `Modern-BERT/` – Experiments involving the Hugging Face model `answerdotai/ModernBERT-base`:
  - `MBERT_embeddings.py` – Extracts sentence embeddings from MD&A sections
  - `MBERT_expansion.py` – Runs model tuning and evaluation across expanding training windows
  - `expanding_sets.py` – Provides utility functions for extracting training and validation subsets
- `PU_Learning/` – Contains the implementation of Elkan & Noto's Positive-Unlabeled (PU) learning algorithm

## Replication Instructions

To replicate the experiments:

1. Install the dependencies listed in `requirements.txt`:

   ```bash
   pip install -r requirements.txt
   ```

2. Download the datasets from this [Google Drive folder](https://drive.google.com/drive/folders/1rjmY48Wy7ZsFDCCNnRm7GiTlKG-nWfjQ?usp=sharing).  
   The folder contains:
   - `fraud_labels.csv`: Label file including all identified fraud cases with descriptions
   - `firm_years.json`: Scraped MD&A data from SEC CIKs (as of May 8, 2025)
   - `firm_years_labels.json`: Firm-year data linked to AAER (Accounting and Auditing Enforcement Releases) CIKs

3. Set up the paths in `amalgamate.py` to point to the downloaded files:

   ```python
   df_labels = pd.read_csv("path/to/fraud_labels.csv")
   mda_path = "path/to/firm_years.json"
   mda_labels_path = "path/to/firm_years_labels.json"
   ```

4. Run `amalgamate.py` to generate both versions of the unified dataset for training and analysis.

5. Run any of the analysis scripts (`classifier.py`, `MBERT_expansion.py`, etc.) to replicate results from the report.